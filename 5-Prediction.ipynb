{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505df818",
   "metadata": {},
   "source": [
    "*This jupyter notebook is part of Arizona State University's course CAS 523 (Methods for Complex Systems Science: Statistics and Dimensionality Reduction) and was written by Bryan Daniels. It was last updated September 15, 2022.*\n",
    "\n",
    "*This assignment uses publicly available data from the following publication: Sosna MMG, Twomey CR, Bak-Coleman J, Poel W, Daniels BC, Romanczuk P, Couzin ID. 2019. [Individual and collective encoding of risk in animal groups](https://www.pnas.org/doi/10.1073/pnas.1905585116). _Proceedings of the National Academy of Sciences._ 116(41): 20556-20561.  The full dataset is available here: https://doi.org/10.5061/dryad.sn02v6x5x.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7ece5",
   "metadata": {},
   "source": [
    "# Using regression to find predictors of decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266ccd7",
   "metadata": {},
   "source": [
    "In this exercise, we will practice using statistical regression to make predictions about a complex system.  We will also use regularization to produce a regression that is easier to interpret.\n",
    "\n",
    "The data we will work with come from a collaboration with a group of biologists interested in the collective movement of animals.  Here, they observed a school of fish (Golden shiners) in shallow water.  The lab setup was isolated so that there were minimal visual or audio cues coming from the external environment.  In this environment, the schools typically had relatively boring schooling behavior, but every once in a while one fish would suddenly become startled.  Their sudden movement would sometimes induce other fish to also startle, and these startling cascades could spread through the school.\n",
    "\n",
    "Our question here is: What cues from startled neighbors are individual fish using to decide whether to startle themselves?  \n",
    "\n",
    "For this exercise, we will focus on using data to determine predictors of startling behavior.  In our research, we used such an analysis to build a quantitative model of startling cascades.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73e527",
   "metadata": {},
   "source": [
    "## Get set up and load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ccc9a",
   "metadata": {},
   "source": [
    "First load our usual set of standard packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18}) # increases font size on plots\n",
    "from pathlib import Path # to handle file paths across all operating systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ab6f43",
   "metadata": {},
   "source": [
    "Now load the dataset we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321648e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path('data/SosnaEtAl2022/first_responders_srk1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4babe5b",
   "metadata": {},
   "source": [
    "Take a look at what the data include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaac4da",
   "metadata": {},
   "source": [
    "These data are focused on so-called \"first responders\".  The basic format is that each startle cascade has a unique identifier given in `Event_raw`.  For each startle cascade, initiated by some individual fish in the school, these data contain information about which fish (if any) was the *first to respond* by startling itself.  This first responder is identified by a row of the data where `Response` has a value of 1.  There are also rows corresponding to the other fish that did *not* respond first to the initial startle, identified by rows of the data where `Response` has a value of 0.\n",
    "\n",
    "The other columns we will focus on here are potential predictors of being a first responder: the column `Dist_metric` and all columns to the right of that.  The exact meaning of each is not so important for this exercise, but in case you are interested, here are the descriptions from the `README.md` file:\n",
    "\n",
    "* `Dist_metric`: metric distance between initiator and fish\n",
    "* `Log_dist_metric`: the log (base 10) of metric distance\n",
    "* `Dist_topological`: the topological distance, i.e. ranked metric distance. If the initiator was the closest fish to the focal individual, topological distance would be 1.\n",
    "* `Ang_area`: the angular area subtended by the initiator on the focal fish\n",
    "* `Rank_area`: the rank of the angular area subtended by the initiator on the focal fish. If the initiator takes up the most area in the focal's vision, rank area is 1.\n",
    "* `Loom`: the change in angular area of the initiator on the focal fish from the frame prior to the startle through 10 frames after (FPS = 120)\n",
    "* `Log_loom`: the log (base 10) of loom\n",
    "* `Ang_pos`: the angle (in radians) between the head of the initiator and the head of the focal. This measures whether the initiator was to the left of the focal, in front of it, behind it, etc.\n",
    "* `Heading`: the absolute value of the angle of the initiator relative to the focal individual. 0 indicates facing the same direction, pi indicates facing opposite directions. Wraps at 2*pi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c30c471",
   "metadata": {},
   "source": [
    "(A video of one of the startle cascades is available [here](https://www.pnas.org/doi/suppl/10.1073/pnas.1420068112/suppl_file/pnas.1420068112.sm01.mp4) if you want to visualize what's going on.  The initiator is red and the fish that can see the initiator are blue.  See if you can spot the first responder.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e8c4a9",
   "metadata": {},
   "source": [
    "We have a good amount of data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502426e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"In this dataset, we have {} examples of fish behavior (startling or not startling) \"\\\n",
    "      \"from {} startle cascades.\".format(len(data),len(data['Event_raw'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc62d9c",
   "metadata": {},
   "source": [
    "Let's split our data explicitly into the thing we are trying to predict (the `Response` column) and the potential predictors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "responseData = data['Response']\n",
    "predictorData = data.loc[:,'Dist_metric':]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6879201",
   "metadata": {},
   "source": [
    "Finally, in our exercise we will test how well our regression can do at predicting which fish will respond first.  To do this, we will fit our regression parameters to about half the data (the \"training set\") and see how well the regression can predict which fish are the first responders in the other data that we haven't used in the fit (the \"test set\").  \n",
    "\n",
    "Here we split both the response and predictor data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrain = 7200 # the number of data rows we will use as training data\n",
    "\n",
    "# training set = first numTrain rows\n",
    "dataTrain = data.iloc[:numTrain]\n",
    "responseDataTrain,predictorDataTrain = responseData.iloc[:numTrain],predictorData.iloc[:numTrain]\n",
    "# test set = all remaining rows\n",
    "dataTest = data.iloc[numTrain:] \n",
    "responseDataTest,predictorDataTest = responseData.iloc[numTrain:],predictorData.iloc[numTrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4392784",
   "metadata": {},
   "source": [
    "❓ **Why is it safer to test our method's ability to predict responses in the test data as opposed to the training data?  How is this connected to the idea of predictable patterns in the data versus unpredictable noise?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab90b5",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89ee7d",
   "metadata": {},
   "source": [
    "## Perform logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1361e0be",
   "metadata": {},
   "source": [
    "Since we have continuous predictors and a binary output (startled versus not startled), logistic regression is a good candidate for fitting a simple model.  \n",
    "\n",
    "Recall that logistic regression fits linear coefficients that multiply each predictor variable and are then summed up—similar in a sense to PCA.  The difference from PCA is that we are \"working in log space\" (hence the logistic part of the name), so that this sum is proportional to the logarithm of the ratio of probabilities of startled versus not startled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a79f73",
   "metadata": {},
   "source": [
    "Logistic regression is performed by `sklearn`'s function `linear_model.LogisticRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f36fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466fdf84",
   "metadata": {},
   "source": [
    "We'll first run vanilla logistic regression with no regularization \"penalty\" (hence `penalty='none'`).  \n",
    "\n",
    "(Side technical note: The algorithm for finding the best fit parameters is iterative, and I've used `max_iter=1000` here to allow the algorithm to converge to the best solution.  The default `max_iter=100` is quicker to run but does not allow enough iterations for full convergence.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc4176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LogisticRegression(penalty='none',max_iter=1000)\n",
    "regressionResults = regression.fit(predictorDataTrain,responseDataTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c81a60",
   "metadata": {},
   "source": [
    "We can look at the resulting fit parameters for coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d301190",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.Series(regressionResults.coef_[0],index=predictorDataTrain.columns)\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9679af9",
   "metadata": {},
   "source": [
    "Using the fit regression, we can also ask for the probability of startling versus not startling for a particular case of predictors.  For instance, the predictors for the first three training data points look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b386187",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorDataTrain.iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee5801",
   "metadata": {},
   "source": [
    "We can insert this into the function `results.predict_proba` to compute the regressed model's predictions for the probability of startling and not startling for each of the three cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionResults.predict_proba(predictorDataTrain.iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3973b",
   "metadata": {},
   "source": [
    "We see that the estimated probabilities of not startling (the first column) are much larger than startling (the second column) for these caess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1ddd4",
   "metadata": {},
   "source": [
    "To get a feeling for how these probabilities depend on the values of the predictors, here's a plot for the probabilities as a function of a changing log distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "logDistList = np.linspace(-3,3)\n",
    "predictorsList = [predictorDataTrain.iloc[0]+np.array([0,logDist,0,0,0,0,0,0,0]) for logDist in logDistList]\n",
    "probs = regressionResults.predict_proba(predictorsList)\n",
    "plt.plot(logDistList,probs)\n",
    "plt.legend(['No startle','Startle'])\n",
    "plt.xlabel('Log distance')\n",
    "plt.ylabel('Probability');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17cc7a6",
   "metadata": {},
   "source": [
    "❓ **Does this plot make intuitive sense based on how you would expect fish to behave?** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c85863",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ff27c",
   "metadata": {},
   "source": [
    "## Try to predict first startlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac55102",
   "metadata": {},
   "source": [
    "One way we can test our model is to see whether it can correctly predict which fish will be the first to respond to the initial startle in a trial, given the values of the predictors for all the fish.\n",
    "\n",
    "I wrote the following function to extract from the data the first fish that actually responded in each trial (for trials that had a responder), as well as the regression's prediction for which fish is the most likely to respond first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640fc6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trueAndPredictedFirstStartles(data,regressionResults):\n",
    "    # record and predict first startlers in training data\n",
    "    firstStartler,firstStartlerPredicted = [],[]\n",
    "    for event in data['Event_raw'].unique():\n",
    "        # restrict to data in a single cascade event\n",
    "        dataEvent = data[data['Event_raw']==event]\n",
    "        if len(dataEvent[dataEvent['Response']==1]) > 0:\n",
    "            # if a responding fish startled, record it:\n",
    "            # record startler as index of fish with response=1\n",
    "            startler = dataEvent[dataEvent['Response']==1].index[0]\n",
    "\n",
    "            # now use regression to predict the first startler\n",
    "            dataEventPredictors = dataEvent.loc[:,'Dist_metric':]\n",
    "            predictedProbs = regressionResults.predict_proba(dataEventPredictors)[:,1]\n",
    "            startlerPredicted = dataEvent.index[np.argmax(predictedProbs)]\n",
    "\n",
    "            firstStartler.append(startler)\n",
    "            firstStartlerPredicted.append(startlerPredicted)\n",
    "    return np.array(firstStartler),np.array(firstStartlerPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22f52f",
   "metadata": {},
   "source": [
    "Trying this on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757d90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstStartlers,firstStartlersPredicted = trueAndPredictedFirstStartles(dataTrain,regressionResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ac5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstStartlersPredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstStartlers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443e28f",
   "metadata": {},
   "source": [
    "We see that in many cases, the correct fish is predicted!  This is an indication that our regression is doing something right.  How well is it doing?  The following function calculates the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fec597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionAccuracy(trueStartlers,predictedStartlers):\n",
    "    numCorrect = np.sum(trueStartlers==predictedStartlers)\n",
    "    numTotal = len(trueStartlers)\n",
    "    print('Proportion of trials with a correct prediction = {}'.format(numCorrect/numTotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffea11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAccuracy(firstStartlers,firstStartlersPredicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd734c1",
   "metadata": {},
   "source": [
    "Now let's compare how we do in predictions using the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a24d47",
   "metadata": {},
   "source": [
    "❓ **Use the functions `trueAndPredictedFirstStartles` and `predictionAccuracy` as above to compute the accuracy of our regression's predictions in the test data that we held out above.** *Hint: We called the test data `dataTest` and the training data `dataTrain`.  Do a sanity check: Do you expect the test accuracy to be larger or smaller than the training accuracy?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72655735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e94e59c",
   "metadata": {},
   "source": [
    "## Compare non-regularized to regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da4c90",
   "metadata": {},
   "source": [
    "Now let's use a regularizer to \"penalize\" having many fit coefficients that are nonzero.  The following code performs the regression with a relatively strong L1 penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8063edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressionReg = LogisticRegression(C=0.01,penalty='l1',max_iter=10000,solver='liblinear')\n",
    "regressionResultsReg = regressionReg.fit(predictorDataTrain,responseDataTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71780c82",
   "metadata": {},
   "source": [
    "Looking again at the fit coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffsReg = pd.Series(regressionResultsReg.coef_[0],index=predictorDataTrain.columns)\n",
    "coeffsReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df085da1",
   "metadata": {},
   "source": [
    "❓ **How are the regularized coefficients different from the non-regularized version above?  What are the conceptual advantages of interpreting the regularized case?  How is this related to dimensionality reduction?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345045ef",
   "metadata": {},
   "source": [
    "✳️ **Answer:** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be91af52",
   "metadata": {},
   "source": [
    "❓ **Compute the accuracy of predictions on the test data using this regularized regression.  Do we suffer much in predictive power using the regularized coefficients?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d30be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✳️ **Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9a5f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
